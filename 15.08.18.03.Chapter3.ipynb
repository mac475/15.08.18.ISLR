{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\", \"malgun gothic\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 100%;\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 0.2em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width: 90%;\n",
       "//        margin-left:auto;\n",
       "//        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mac475의 ipython 표준 style을 적용함\n",
    "from IPython.core.display import HTML\n",
    "styles = open(\"styles/custom.css\", \"r\").read()\n",
    "HTML( styles )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $Y \\approx \\beta_0 + \\beta_1X$\n",
    "* $sales \\approx \\beta_0 + \\beta_1 \\times TV$\n",
    "* $\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.1 Estimating the Coefficients\n",
    "* $RSS (Residual Sum of squares)$\n",
    "* $RSS = e_1^2 + e_2^2 + \\cdots + e_n^2 = (y_1-\\hat{\\beta_0}-\\hat{\\beta_1}x_1)^2 + (y_2-\\hat{\\beta_0}-\\hat{\\beta_1}x_2)^2 + \\cdots + (y_n-\\hat{\\beta_0}-\\hat{\\beta_1}x_n)^2$\n",
    "<img src=\"images/p62 figure 3.1.png\" width = \"65%\"/>\n",
    "    $$\\hat{\\beta_1} = \\frac{\\sum\\limits_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})} = \\sum\\limits_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) / \\sum\\limits_{i=1}^n(x_i - \\bar{x})$$\n",
    "  \n",
    "    $$\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1\\bar{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.2 Assesing the Accuracy of the Coefficient Estimates\n",
    "* $Y = f(X) + \\epsilon$\n",
    "* $Y = \\beta_0 + \\beta_1X + \\epsilon, (\\epsilon$ : mean-zero error term) : population regression line (母회귀선, 혹은 참회귀선)\n",
    "* 표준편차 : standard deviation : 各 사례들이 평균에서 얼마나 흩어져 있는가?\n",
    "* 표준오차 : standard error : sampling한 표본의 평균과 모집단 평균과의 차이\n",
    "* $Var(\\hat{\\mu}) = SE(\\hat{\\mu})^2 = \\sigma^2 / n$\n",
    "* 일반적으로 $\\sigma^2$는 알려져 있지 않으나 쉽게 estimation 가능, 이 estimation을 $RSE = \\sqrt{RSS / (n-2)}$\n",
    "* Null hypothesis : 귀무가설 : 내가 증명하고자 하는 가설의 반대가설\n",
    "* p-value : 귀무가설의 지지정도 : 즉, p-value가 낮다 → 귀무가설 가능성 낮다 → 나의 가설이 맞다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1.3 Assessing the Accuracy of the Model\n",
    "####RSE (Residual Standard Error) : error term $\\epsilon$의 standard deviation의 estimation임\n",
    "\n",
    "$$RSE = \\sqrt{\\frac{1}{n-2}RSS} = \\sqrt{\\frac{1}{n-2}\\sum\\limits_{i=1}^n(y_i - \\hat{y_i})^2}$$\n",
    "\n",
    "####$R^2$ Statistic\n",
    "* RSE : response Y값 단위를 기준으로 값을 제공\n",
    "* $R^2$ : 0 ~ 1의 비율값을 제공\n",
    "    $$R^2 = \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS}$$\n",
    "    - (이때, $TSS = \\sum(\\hat{y_i} - \\bar{y})$ : total sum of squares)\n",
    "* 참고 : TSS는 response Y에서의 total variance를 측정, regression 수행전 response로부터 inherent된 variability의 양으로 판단\n",
    "* 참고 : 반대로 RSS는 regression 수행후 설명되지 않는 variability의 양으로 판단\n",
    "* 따라서, TSS - RSS는 response중 explained되는 variant의 amount의 측정량이라 할 수 있음\n",
    "* 그리고, $R^2$는 1에서 ($RSS/TSS$를 제외하므로) X에 의해서 설명가능한 variability의 proportion을 measure한다고 할 수 있음\n",
    "* 즉, 전체 1중에서 RSS에 의한 설명불가 variability의 비율을 제외하므로..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.2 Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiple Linear Regression은 간단히 Simple Linear Regression을 extend한 것으로 본다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 각각의 predictor별로 분리된 slope(기울기) coefficient(계수)를 single model에 가진다고 본다\n",
    "    $$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_pX_p + \\epsilon$$\n",
    "* 따라서, Advertising의 경우 Multiple Linear Regression 표현시\n",
    "    $$sales = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times radio + \\beta_3 \\times newspaper + \\epsilon$$\n",
    "    와 같이 표현가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.2.1 Estimating the Regression Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction Formula : $\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1 + \\hat{\\beta_2}x_2 + \\cdots + \\hat{\\beta_p}x_p$\n",
    "* Parameter들은 Least Squares approach를 통해 estimation되며, 다음과 같이 표현가능\n",
    "    $$RSS = \\sum\\limits_{i=1}^n(y_i - \\hat{y_i})^2 = \\sum\\limits_{i=1}^n(y_i - \\hat{\\beta_0} - \\hat{\\beta_1}x_{i1} - \\hat{\\beta_2}x_{i2} - \\cdots - \\hat{\\beta_p}x_{ip})^2$$\n",
    "* Simple Linear Regression의 경우 $\\hat{\\beta_1}$과 $\\hat{\\beta_0}$는 다음과 같이 계산가능\n",
    "    $$\\hat{\\beta_1} = \\frac{\\sum\\limits_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})} = \\sum\\limits_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) / \\sum\\limits_{i=1}^n(x_i - \\bar{x})$$\n",
    "    $$\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1\\bar{x}}$$\n",
    "* 하지만, Multiple Linear Regression의 경우 계산은 복잡하며 각종 Solution 활용하여 산출\n",
    "* Multiple Linear Regression 시도시, 각 Coefficient들의 값은 반드시 p-value와 함께 검토 필요\n",
    "* 다양한 Coefficient들간의 관계파악을 위해, Correlation matrix를 함께 검토\n",
    "    - Table 3.3의 Simple Linear Regression시 newspaper는 sales에 유의미함 (Coefficient = 0.055, p-value < 0.0001)\n",
    "        <img src=\"images/p72 table 3.3.png\" width = \"65%\"/>\n",
    "    - Table 3.4의 Multiple Linear Regression시 newspaper는 sales에 무의미함 (Coefficient = -0.001, p-value = 0.8599)\n",
    "        <img src=\"images/p74 table 3.4.png\" width = \"65%\"/>\n",
    "    - $\\because$ Table 3.5 Correlation matrix 확인時, newspaper가 아닌 radio, TV에 의한 sales 증가 확인가능\n",
    "        <img src=\"images/p75 table 3.5.png\" width = \"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.2.2 Some Important Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiple Linear Regression 수행시 몇가지 중요한 의문을 가짐\n",
    "  1. $X_1, X_2, \\cdots, X_p$중 하나라도 prediction에 중요한 것이 있는가?\n",
    "  2. 모든 predictor들이 Y를 설명하는가? 혹은 일부 subset predictor들만 의미가 있는가?\n",
    "  3. Model은 얼마나 data에 fitting되어 있는가?\n",
    "  4. predictor value가 주어지는 경우, 어떤 response를 predict하는가? prediction accuracy는 어떤가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####One : Is There a Relationship Between the Response and Predictors?\n",
    "$H_0 : \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0$\n",
    "\n",
    "$H_a$ : 최소한 하나의 $\\beta_j$는 0이 아니다\n",
    "\n",
    "Hypothesis test (가설검정) 위해 F-statistic (F값)을 계산,\n",
    "    $$F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}$$\n",
    "\n",
    "이때,\n",
    "    $$\n",
    "        TSS = \\sum(y_i - \\bar{y})^2, \\quad RSS = \\sum(y_i - \\hat{y_i})^2 \\quad E\\{RSS / (n-p-1)\\} = \\sigma^2 E\\{TSS - RSS / p)\\} = \\sigma^2\n",
    "    $$\n",
    "\n",
    "여기서, 만약 $H_0$가 맞다면, 즉, presictor와 response간 아무런 관계가 없다면, F값 = 1이 됨\n",
    "\n",
    "반면, 만약 $H_a$가 맞다면, $E\\{TSS - RSS / p)\\} > \\sigma^2$가 되여, F값 > 1이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Two : Deciding on Important Variables\n",
    "* p개의 variables가 존재하는 경우, subset의 경우의 수는 $2^p$개임\n",
    "* 따라서, 모든 variables를 대상으로 Model 수행하는 것은 현실적으로 불가능\n",
    "* 이를 극복하기 위한 3가지의 classical approach가 있음\n",
    "    - Forward selection : null model로 시작하여 variables를 하나씩 추가\n",
    "    - Backward selection : all vriables로 시작하여 variables를 하나씩 감소\n",
    "    - Mixed selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Three : Model Fit\n",
    "* Model fit 판단위해 RSE와 $R^2$ 활용\n",
    "* variables 증가시 $R^2$는 언제나 증가\n",
    "* variables 증가시 $RSE$는 일반적으로 증가\n",
    "    $$RSE = \\sqrt{\\frac{1}{n-p-1}RSS}$$\n",
    "    (단, variable개수 p 증가로 인한 $RSS$ 감소가 상대적으로 작은 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Four : Predictions\n",
    "* 실제 모델의 값인 True population regression plane : $f(X) = \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_pX_p$일때\n",
    "* estimation은 : $\\hat{Y} = \\hat{\\beta_0} + \\hat{\\beta_1}X_1 + \\cdots + \\hat{\\beta_p}X_p$이며, 발생되는 inaccuracy는 reducible error에 기인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##3.3 Other Considerations in the Regression Model\n",
    "###3.3.1 Qualitative Predictors\n",
    "####Predictors with Only Two Levels\n",
    "* Credit card balance를 gender별로 분석위해 qualitative data를 임의의 numerical data로 지정\n",
    "$\n",
    "x_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           1 &\\mbox{ if $i$th person is female} \\\\\n",
    "                           0 &\\mbox{ if $i$th person is male}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$라 한다면, 그에따른 model은 다음과 같다\n",
    "$\n",
    "y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           \\beta_0 + \\beta_1 + \\epsilon_i &\\mbox{ if $i$th person is female $\\quad$$\\because x_i = 1$ } \\\\\n",
    "                           \\beta_0 + \\epsilon_1 &\\mbox{ if $i$th person is male $\\quad$$\\because x_i = 0$}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$\n",
    "<img src=\"images/p84 table 3.7.png\" width = \"65%\"/>\n",
    "* 이때, Coefficient 값 존재, p-value가 상당히 크므로 성별에 따른 credit card balance 차이의 통계적 근거는 없다\n",
    "\n",
    "\n",
    "\n",
    "* 또한,\n",
    "$\n",
    "x_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           1 &\\mbox{ if $i$th person is female} \\\\\n",
    "                           -1 &\\mbox{ if $i$th person is male}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$라 한다면, 그에따른 model은 다음과 같다\n",
    "$\n",
    "y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           \\beta_0 + \\beta_1 + \\epsilon_i &\\mbox{ if $i$th person is female $\\quad$$\\because x_i = 1$ } \\\\\n",
    "                           \\beta_0 - \\beta_1 +  \\epsilon_1 &\\mbox{ if $i$th person is male $\\quad$$\\because x_i = -1$}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$\n",
    "        - 이때, qualitative data를 어떠한 값으로 지정하더라도 final prediction은 동일함\n",
    "\n",
    "####Qualitative Predictors with More than Two Levels\n",
    "$\n",
    "x_{i1} = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           1 &\\mbox{ if $i$th person is Asian} \\\\\n",
    "                           0 &\\mbox{ if $i$th person is not Asian}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "x_{i2} = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           1 &\\mbox{ if $i$th person is Caucasian} \\\\\n",
    "                           0 &\\mbox{ if $i$th person is not Caucasian}\n",
    "              \\end{array}\n",
    "      \\right.      \n",
    "$라 하면,\n",
    "$\n",
    "y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\epsilon_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           \\beta_0 + \\beta_1 + \\epsilon_i &\\mbox{ if $i$th person is Asian } \\\\\n",
    "                           \\beta_0 + \\beta_2 + \\epsilon_i &\\mbox{ if $i$th person is Caucasian } \\\\\n",
    "                           \\beta_0 + \\epsilon_1 &\\mbox{ if $i$th person is African American}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$\n",
    "<img src=\"images/p84 table 3.7.png\" width = \"65%\"/>\n",
    "* 이때, Coefficient 값 존재, p-value가 상당히 크므로 성별에 따른 credit card balance 차이의 통계적 근거는 없다\n",
    "\n",
    "\n",
    "\n",
    "* 또한,\n",
    "$\n",
    "x_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           1 &\\mbox{ if $i$th person is female} \\\\\n",
    "                           -1 &\\mbox{ if $i$th person is male}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$라 한다면, 그에따른 model은 다음과 같다\n",
    "$\n",
    "y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i = \\left\\{\n",
    "              \\begin{array}{rl}\n",
    "                           \\beta_0 + \\beta_1 + \\epsilon_i &\\mbox{ if $i$th person is female $\\quad$$\\because x_i = 1$ } \\\\\n",
    "                           \\beta_0 - \\beta_1 +  \\epsilon_1 &\\mbox{ if $i$th person is male $\\quad$$\\because x_i = -1$}\n",
    "              \\end{array}\n",
    "      \\right.\n",
    "$\n",
    "<img src=\"images/p86 table 3.8.png\" width = \"65%\"/>\n",
    "* 이때, 민족별 Coefficient 값 존재, p-value가 크므로 민족별 credit card balance 차이의 통계적 근거는 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###3.3.2 Extentions of the Linear Model\n",
    "* Linear Regression은 매우 훌륭한 tool이나, 두가지 restrictive assumption이 있음\n",
    "    - Predictor와 Response는 additive임 : predictor $X_j$ 변화로 인한 효과는 다른 predictor들과 independent함\n",
    "    - Predictor와 Response는 linear임 : $X_j$ 한 단위 변화로 인한 Y값의 변화는 constant임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Removing the Additive Assumption\n",
    "* 기본적으로 Linear Model은 각 predictor들의 response에 대한 효과가 independent하다고 봄\n",
    "* 하지만, 각 predictor가 상호 영향을 주는 경우가 real world에서는 발생\n",
    "* 이를 marketing에서는 synergy라 표현하며, statistics에서는 interaction이라 표현\n",
    "\n",
    "\n",
    "* $Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon$이라는 2개의 variables를 가지는 linear regression model 가정시\n",
    "    * interaction 효과허용을 위한 model확장을 위해, 3번째의 predictor를 다음과 같이 사용\n",
    "    \n",
    "    $Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_1X_2 + \\epsilon$은 아래와 같이 표현가능\n",
    "    \n",
    "    $Y = \\beta_0 + (\\beta_1 + \\beta_3X_2)X_1 + \\beta_2X_2 + \\epsilon$\n",
    "    \n",
    "    $\\space\\space\\space= \\beta_0 + \\tilde{\\beta_1}X_1  + \\beta_2X_2 + \\epsilon$이 되어, $\\tilde{\\beta_1} = \\beta_1 + \\beta_3X_2$이므로, 이제 $\\tilde{\\beta_1}$은 $X_2$의 변화에 따라 변함\n",
    "    \n",
    "* 따라서, Advertising example은 다음과 같이 표현가능\n",
    "\n",
    "    $sales = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times radio + \\beta_3 \\times (radio \\times TV) + \\epsilon$\n",
    "    \n",
    "    $\\space\\space\\space\\space\\space\\space\\space\\space= \\beta_0 + (\\beta_1 + \\beta_3 \\times radio) \\times TV + \\beta_2 \\times radio + \\epsilon$\n",
    "\n",
    "* 그러므로, $\\beta_3$를 radio ad 한단위 증가로 인한 TV ad 증가효과라고 해석가능\n",
    "* Hierarchical principle : 만약 interaction이 model에 포함된다면, main effect들도 모두 model에 포함시켜야 함 (p-value가 크더라도...)\n",
    "\n",
    "\n",
    "* interaction은 quantitative와 qualitative 사이에도 다음과 같이 반영가능\n",
    "$\n",
    "balance_i \\approx \\beta_0 + \\beta_1 \\times income_i + \n",
    "              \\left\\{\n",
    "                  \\begin{array}{rl}\n",
    "                               \\beta_2 &\\mbox{ if $i$th person is a student} \\\\\n",
    "                               0 &\\mbox{ if $i$th person is not a student}\n",
    "                  \\end{array}\n",
    "              \\right.\n",
    "\\\\\n",
    "\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\n",
    "= \\beta_1 \\times income_i + \n",
    "              \\left\\{\n",
    "                  \\begin{array}{rl}\n",
    "                               \\ \\beta_0 + \\beta_2 &\\mbox{ if $i$th person is a student} \\\\\n",
    "                               \\beta_0 &\\mbox{ if $i$th person is not a student}\n",
    "                  \\end{array}\n",
    "              \\right.\n",
    "$\n",
    "\n",
    "* 하지만, 이는 income 변화에 따라 학생/ 일반인의 balance 변화가 다를 수 있다는 점을 반영하지 않고 있음\n",
    "    * 따라서, 이를 qualitative인 income과 quantitative인 student간의 multiply (interaction) 적용통해 해소가능\n",
    "$\n",
    "balance_i \\approx \\beta_0 + \\beta_1 \\times income_i + \n",
    "              \\left\\{\n",
    "                  \\begin{array}{rl}\n",
    "                               \\beta_2 + \\beta_3 \\times income_i &\\mbox{ if student} \\\\\n",
    "                               0 &\\mbox{ if not student}\n",
    "                  \\end{array}\n",
    "              \\right.\n",
    "\\\\\n",
    "\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\n",
    "=           \\left\\{\n",
    "                  \\begin{array}{rl}\n",
    "                               \\ (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) \\times income_1 &\\mbox{ if student} \\\\\n",
    "                               \\beta_0 + \\beta_1 \\times income_i &\\mbox{ if not student}\n",
    "                  \\end{array}\n",
    "              \\right.\n",
    "$\n",
    "    * 최종적으로 학생/ 일반인 여부에 따라 income 증가에 따른 slope(기울기) 변화가 상이할 수 있음\n",
    "    \n",
    "    <img src=\"images/p90 figure 3.7.png\" width = \"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####Non-linear Relationships\n",
    "* non-linear relationships의 표현시 polynorminal regression (다항회귀) 활용\n",
    "* 예를들어 mpg (mile per gallon)과 horsepower의 관계를 $mpg = \\beta_0 + \\beta_1 \\times horsepower + \\beta_2 \\times horsepower^2 + \\epsilon$\n",
    "과 같이 표현\n",
    "    * 하지만, 이것 역시 $X_1 = horsepower$이고, $X_2 = horsepower^2$인 linear model임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.3.3 Potential Problems\n",
    "* Linear Regression 수행시 발생가능한 문제는 다음과 같다\n",
    "\n",
    "\n",
    "1. Non-linearity of the response-predictor relationships\n",
    "2. Correlation of error terms\n",
    "3. Non-constant variance of error terms\n",
    "4. Outliers\n",
    "5. High-leverage points\n",
    "6. Collineariry\n",
    "\n",
    "####1. Non-linarity of the Data\n",
    "* Residual plots 활용하여 dataset의 non-linearity를 확인\n",
    "* 만약, residual plot 통해 non-linear 관계가 확인되면, 간단히 시도가능한 접근은 $logX, \\sqrt{X}, X^2$와 같이 predictor를 변형하여 model에 활용\n",
    "\n",
    "####2. Correlation of Error Terms\n",
    "* Linear regression의 중요한 가정 : error terms $\\epsilon_1,\\epsilon_2,\\cdots,\\epsilon_n$간 correlation 없음\n",
    "\n",
    "####3. Non-constant Variance of Error Terms (오차)\n",
    "* 오차(Error term)는 일정한 분산을 가져야 함 : $Var(\\epsilon_i) = \\sigma^2$\n",
    "* 만약, 그렇지 못한 경우 response Y에 대해 concave function (오목함수) 적용하여 transformation 수행 : $logY, \\sqrt{Y}$\n",
    "* 아래 좌측의 경우 각 $x$값마다의 오차범위가 다르며, 우측의 경우 $log$ transformation되어 heteroscedasticity (이분산성)을 극복함\n",
    "<img src=\"images/p93 figure 3.9.png\" width = \"65%\"/>\n",
    "\n",
    "####4. Outliers\n",
    "* Outlier : model에 의해 predict된 값 $\\hat{y}_i$과 $y_i$간에 차이가 현격하게 발생하는 것들\n",
    "* Outlier 식별방법 : studentized residual의 절대값이 3보다 크면 outlier로 식별한다\n",
    "\n",
    "####5. High Leverage Points\n",
    "* High Leverage Point : predictor $x_i$의 이상치\n",
    "* 일반적으로 response $y_i$의 이상치인 outlier보다, $x_i$의 이상치인 high leverage point가 least squares line에 대한 impact가 크다\n",
    "* leverage statistic 계산 : leverage statistic이 크면 high leverage이다\n",
    "  $h_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum\\limits_{ i\\prime = 1}^n(x_i\\prime - \\bar{x} )^2 }$\n",
    "* leverage statistic의 범위 : $1/n \\le h_i \\le 1$, average leverage = $(p + 1)/n$\n",
    "* 만약, leverage statistic이 $(p + 1)/n > 1$면, high leverage로 판단가능\n",
    "\n",
    "####6. Collinearity\n",
    "* Collineariry : 2개 이상의 predictor가 서로 연관되어 있는 것\n",
    "* Collinearity는 regression coefficient들에 대한 estimation 정확도를 감소시킴\n",
    "* Collinearity 식별은 correlation matrix 활용 : matrix내의 절대값이 크다면 highly correlated임\n",
    "* 여러 predictor들간 발생하는 collinearity를 multicollinearity라 함\n",
    "* VIF (variance inflation factor) 계산통해 multicollinearity 계산가능\n",
    "* $VIF = 1$ (collinearity가 전혀 없는 상태), $5 < VIF < 10$ : 문제되는 상황\n",
    "* <img src=\"images/p102 function.png\" width = \"20%\"/>\n",
    "* Collinearity 발생시 해결방법\n",
    "    1. one of problematic variable의 제거\n",
    "    2. collinear variable을 single predictor로 combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.4 The Marketing Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.5 Comparison of Linear Regression with K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\hat{f}(x_0) = \\frac{1}{K}\\sum\\limits_{x_1 \\in \\nu_0}y_i$ (이때, $x_0$는 $\\nu_0$라 표현되는 K개의 observation과 가장 가깝다)\n",
    "* K값은 bias - variance tradeoff 관계임\n",
    "* K가 작으면, most flexible이고 low bias이나 high variance이며\n",
    "* K가 크면, smoother이고 high bias이나 low variance이다\n",
    "* 이후 Chapter 5에서 test error estimation에 대한 접근을 통해, KNN regression에서의 최적 K값 식별방법을 알아본다\n",
    "\n",
    "* (실제 relationship이 unknown인) 대부분의 현실세계에서는, KNN이 linear regression보다 선호되곤 함\n",
    "    1. 만약 실제 relationship이 linear라 해도, KNN은 약간 모자를 것이며,\n",
    "    2. 만약 실제 relationship이 non-linear인 경우, KNN은 매우 양호한 결과를 제공함\n",
    "    \n",
    "    <img src=\"images/p107 figure 3.17.png\" width = \"65%\"/>\n",
    "    <img src=\"images/p107 figure 3.18.png\" width = \"65%\"/>\n",
    "    <img src=\"images/p108 figure 3.19.png\" width = \"65%\"/>\n",
    "    \n",
    "    * 3.17 ~ 3.18 실제 relationship이 linear인 경우, K가 아주 커야만 linear MSE와 근접이나마 가능\n",
    "    * 3.19 ~ 3.20 실제 relationship이 slightly non linear, strongly non linear인 경우 KNN은 양호한 performance를 제공\n",
    "    \n",
    "    <img src=\"images/p109 figure 3.20.png\" width = \"65%\"/>\n",
    "    \n",
    "    * predictor $p$의 증가에 따라 KNN fit의 MSE가 매우 급상승하는 poor 효과를 보여줌\n",
    "    * 하지만, parametric인 linear의 경우, 큰 변화를 보이지 않음 (parametric이 non-parametric을 outperform함)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
